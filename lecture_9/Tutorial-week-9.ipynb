{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cdc0286",
   "metadata": {},
   "source": [
    "# Tutorial Week 9 - Bagging, Boosting and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c629bf-0240-491a-8d8c-835d9b30c0fa",
   "metadata": {},
   "source": [
    "## Question 1 \n",
    "\n",
    "#### We consider the forest canopy height data discussed in lectures from the spNNGP R package\n",
    "\n",
    "https://cran.r-project.org/web/packages/spNNGP/index.html\n",
    "\n",
    "#### A random subset of 5000 observations from the original data set will be used.  To get started you can import the following packages and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81f26aa-af94-4ac0-b9a3-a885316037ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import sklearn.model_selection as skm\n",
    "from sklearn.tree import (DecisionTreeClassifier as DTC,\n",
    "                          DecisionTreeRegressor as DTR,\n",
    "                          plot_tree)\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.ensemble import \\\n",
    "    (RandomForestRegressor as RF,\n",
    "     GradientBoostingRegressor as GBR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97039d7d-b427-4ddf-b139-1ab4572ecbc1",
   "metadata": {},
   "source": [
    "#### You can read in the data as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4079fe3d-906e-484a-be42-39c9f64fd070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Easting</th>\n",
       "      <th>Northing</th>\n",
       "      <th>FCH</th>\n",
       "      <th>PTC</th>\n",
       "      <th>holdout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277.533541</td>\n",
       "      <td>1653.934914</td>\n",
       "      <td>12.53</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270.594000</td>\n",
       "      <td>1648.405211</td>\n",
       "      <td>7.05</td>\n",
       "      <td>77.353405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>271.879366</td>\n",
       "      <td>1649.589274</td>\n",
       "      <td>11.64</td>\n",
       "      <td>46.062416</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275.259678</td>\n",
       "      <td>1653.927843</td>\n",
       "      <td>9.80</td>\n",
       "      <td>43.476361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>259.515725</td>\n",
       "      <td>1646.266058</td>\n",
       "      <td>15.49</td>\n",
       "      <td>81.627211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Easting     Northing    FCH        PTC  holdout\n",
       "0  277.533541  1653.934914  12.53  76.000000        1\n",
       "1  270.594000  1648.405211   7.05  77.353405        1\n",
       "2  271.879366  1649.589274  11.64  46.062416        0\n",
       "3  275.259678  1653.927843   9.80  43.476361        0\n",
       "4  259.515725  1646.266058  15.49  81.627211        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BCEF = pd.read_csv('BCEF.csv',header=0,names=[\"Easting\",\"Northing\",\"FCH\",\"PTC\",\"holdout\"])\n",
    "BCEF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0802708f-dee4-45e9-a7f4-708c5e335495",
   "metadata": {},
   "source": [
    "#### FCH is the response of interest (forest canopy height, in metres) and we will model FCH in terms of the Easting and Northing.  Answer the following questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda2cb0d-d736-4f49-9b29-8bd799005039",
   "metadata": {},
   "source": [
    "- #### a) Fit a regression tree using all the training data without pruning to predict FCH using Easting and Northing.  We consider the tree without pruning, since unpruned trees are used for bagging.  \n",
    "- #### b) Plot the predictions of the fitted tree over the convex hull of the Easting and Northing.  If reg is your regression tree, and X is a pandas data frame containing the features ``Easting`` and ``Northing``, some code to do this is given below. See if you can understand the code by reading the help.\n",
    "\n",
    "        xp = np.linspace(X['Easting'].min(), X['Easting'].max(), 100)  \n",
    "        yp = np.linspace(X['Northing'].min(), X['Northing'].max(), 100)  \n",
    "        Xm, Ym = np.meshgrid(xp, yp) \n",
    "        X_reshaped = Xm.flatten().reshape(-1, 1)  \n",
    "        Y_reshaped = Ym.flatten().reshape(-1, 1)  \n",
    "        features = np.concatenate((X_reshaped, Y_reshaped), axis=1)  \n",
    "        features = pd.DataFrame(features, columns=X.columns)\n",
    "        Z = reg.predict(features).reshape(Xm.shape)\n",
    "\n",
    "        subset_points = np.column_stack((np.array(X['Easting']),np.array(X['Northing'])))\n",
    "        hull = ConvexHull(subset_points)\n",
    "        mask = np.ones_like(Xm, dtype=bool)\n",
    "        for eq in hull.equations:\n",
    "            mask &= (Xm * eq[0] + Ym * eq[1] + eq[2] <= 0)\n",
    "        X_masked = np.ma.masked_array(Xm, mask=~mask)\n",
    "        Y_masked = np.ma.masked_array(Ym, mask=~mask)\n",
    "        Z_masked = np.ma.masked_array(Z, mask=~mask)\n",
    "\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        levels = 8\n",
    "        cmap = \"Blues\"  \n",
    "        CS = ax.contourf(X_masked, Y_masked, Z_masked, levels, cmap=cmap)\n",
    "        ax.clabel(CS, inline=True, fontsize=10)\n",
    "        ax.plot(X['Easting'], X['Northing'], 'ko', markersize=1)\n",
    "        ax.set_title('Regression tree fit with no pruning')\n",
    "        cbar = fig.colorbar(CS)\n",
    "        cbar.set_label('FHC')\n",
    "        \n",
    "- #### c) Repeat the above analysis using bagging.  Experiment with different values for B.\n",
    "- #### d) Repeat the above analysis with boosting using stumps (set ``max_depth=1``).  Experiment with different values for B and $\\lambda$.  As mentioned in lectures, boosting with stumps corresponds to an additive model.  Can you explain why?\n",
    "- #### e) Repeat the above analysis with boosting using ``max_depth=2``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00dd295",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937abb8c",
   "metadata": {},
   "source": [
    "#### We consider once again the Singlish example from last lecture.  We will see if we can improve on a classification tree using bagging, random forests and gradient boosting.  To start we do the following imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9c5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import sklearn.model_selection as skm\n",
    "from sklearn.tree import (DecisionTreeClassifier as DTC,\n",
    "                          DecisionTreeRegressor as DTR,\n",
    "                          plot_tree,\n",
    "                          export_text)\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             log_loss)\n",
    "from sklearn.ensemble import \\\n",
    "     (RandomForestRegressor as RF,\n",
    "      GradientBoostingRegressor as GBR,\n",
    "      RandomForestClassifier as RFC,\n",
    "      GradientBoostingClassifier as GBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f20b94f",
   "metadata": {},
   "source": [
    "#### Read in Singlish data to a pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c620d302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>e</th>\n",
       "      <th>h</th>\n",
       "      <th>s</th>\n",
       "      <th>g</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>label</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>S</td>\n",
       "      <td>Act blur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>S</td>\n",
       "      <td>Agak agak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>S</td>\n",
       "      <td>Aiyoh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>S</td>\n",
       "      <td>Alamak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>S</td>\n",
       "      <td>Arrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a    e    h    s     g         l         m label     phrase\n",
       "0  0.142857  0.0  0.0  0.0  0.00  0.142857  0.000000     S   Act blur\n",
       "1  0.500000  0.0  0.0  0.0  0.25  0.000000  0.000000     S  Agak agak\n",
       "2  0.200000  0.0  0.2  0.0  0.00  0.000000  0.000000     S      Aiyoh\n",
       "3  0.500000  0.0  0.0  0.0  0.00  0.166667  0.166667     S     Alamak\n",
       "4  0.200000  0.0  0.0  0.0  0.00  0.000000  0.000000     S      Arrow"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Singlish = pd.read_csv('Singlish.csv')\n",
    "Singlish.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa8dcee",
   "metadata": {},
   "source": [
    "- #### a) Split the data into training and test, 50%/50%.  \n",
    "- #### b) Fit a classification tree to the training data, using cost-complexity pruning, and examine the accuracy on the test data.\n",
    "- #### c) Construct a classifier using bagging using the ``RandomForestClassifier`` function, which works similarly to the ``RandomForestRegressor`` function that we discussed last week.  Try different values for B, and examine the accuracy on the test data. \n",
    "- #### d) Construct a classifier using boosting using the ``GradientBoostingClassifier`` function, which works similarly to the ``GradientBoostingRegressor`` function that we used last week.  Try varying B and $\\lambda$, and examine the accuracy on the test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c043e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
