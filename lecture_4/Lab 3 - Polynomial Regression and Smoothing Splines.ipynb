{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6adb71f6",
   "metadata": {},
   "source": [
    "# Lab 3: Visualizing nonlinear regression\n",
    "\n",
    "Data science is a visual practice. Visualizing your models and their prediction (and their errors) so that you can communicate findings and limitations well is 50% of the job.\n",
    "\n",
    "We will recreate much of the models shown in class. First load and look through the motorcycle dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b60e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('motorcycle.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35929a19",
   "metadata": {},
   "source": [
    "The dataset column 'times' is the time since impact and 'accel' is the acceleration of the rider's head in g (gravitational force).\n",
    "\n",
    "The dataset has some duplicated times, and without a way to really interpret what those mean, we should remove them as some methods do not really deal with those well. The following line removes any entries with duplicated 'times' values (keeping only the first to appear)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebfe29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~ df['times'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e762dd88",
   "metadata": {},
   "source": [
    "Now we can plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbca230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='times', y='accel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e517c",
   "metadata": {},
   "source": [
    "## Polynomial regression\n",
    "\n",
    "The first model to fit is polynomial regression. You saw in lecture that polynomial regression (like all basis expansion methods) are simply fit by linear regression with an appropriately constructed basis. \n",
    "\n",
    "### Problem 1\n",
    "Use the method 'sklearn.preprocessing.PolynomialFeatures' to construct those bases and fit a few different polynomials of differing degrees and plot them to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da2f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The import statements below are to help you. If you read the documentation, you will see PolynomialFeatures\n",
    "is used like this:\n",
    "\n",
    "    pr = PolynomialFeatures(degree=3)  # for a degree 3 polynomial\n",
    "    X_polynomial = pr.fit_transform(X)\n",
    "    \n",
    "Note that, even though we are only dealing with univariate inputs, most scikit-learn routines expect a 2-D matrix\n",
    "to make predictions.\n",
    "\n",
    "For a column of a dataframe, you can make sure you have that by doing:\n",
    "\n",
    "    X = df['times'].to_frame()\n",
    "    \n",
    "Or for a numpy array, you can use\n",
    "\n",
    "    x_line = np.linspace(0, 60, 1000)  # this is just a 1-D array of shape (1000,)\n",
    "    x_line_2d = x_line.reshape(-1, 1)  # this is now a 2-D array of shape (1000, 1)\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90325e9c",
   "metadata": {},
   "source": [
    "## Regression splines\n",
    "\n",
    "It is better to use (natural) cubic regression splines. These are the most popular of all regression splines used in practice. scipy (a scientific programming package that is similar to Numpy and Pandas and is built-in to most Python distributions) has a method 'scipy.interpolate.UnivariateSpline' for natural cubic regression splines.\n",
    "\n",
    "### Problem 2\n",
    "Fit a natural cubic regression spline with various regularization parameters, which are called 's' in the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ca0ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "After importing, you create and fit the model like:\n",
    "\n",
    "    s = 100 * len(X)  # the regularization parameter... you can play around with different values\n",
    "    spl = UnivariateSpline(X, Y, s=s)\n",
    "    y_pred = spl(x_test)  # to make predictions. Here x_test can be a 1-D array.\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "from scipy.interpolate import UnivariateSpline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120466ce",
   "metadata": {},
   "source": [
    "The natural next step is to choose a good value for the penalty parameter via cross validation. Because this is a relatively small dataset, we probably want to use K-fold cross validation, which uses up as much of the data as possible.\n",
    "\n",
    "We can not use the cross-validation helper introduced in Lab 2 (last week) so easily, because we are not using a scikit-learn model to for the smoothing spline. So instead we can use another scikit-learn cross-validation helper for K-fold cross-validation: 'sklearn.model_selection.KFold'.\n",
    "\n",
    "### Problem 3\n",
    "Use cross-validation to select a good value of the penalization parameter for the smoothing spline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ba5b37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10)  # K-fold cross validation\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(train_index)\n",
    "    print(test_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca86df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
