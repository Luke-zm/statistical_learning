{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "This notebook is for the assignment 2 of the module ST5227, statistical learning.\n",
    "\n",
    "Contents:   \n",
    "[Problem 1](#Problem-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "During our lab in Lecture 2 (on Linear Models and Regularization), we ran an experiment\n",
    "to compare linear regression with ordinary least squares, ridge regression, and the lasso\n",
    "on predicting diabetes disease progression. It was noted at the end of the lab that there\n",
    "did not appear to be strong evidence that any model was significantly outperforming\n",
    "the other. This was exemplified when we saw the following plot:    \n",
    "![Fig 1](./figs/fig_1.png)    \n",
    "However, if you ran this experiment again, you may find that the results change. How\n",
    "do we interpret this? This happens due to noise and possibly due to the limitations of\n",
    "the models we are using. This result further highlights the uncertainty these models\n",
    "have when making predictions on this dataset. How can we try to explore this further?\n",
    "One idea is to increase the number of cross-validation splits (in attempts to decrease our\n",
    "uncertainty in our estimates). Rerun the experiment with an increased number of cross\n",
    "validation splits and analyze your results. Consider using hypothesis tests, such as the\n",
    "paired t-test with something like:    \n",
    "from scipy.stats import ttest_rel     \n",
    "p_ = ttest_rel(errors_lr, errors_ridge).pvalue     \n",
    "print(\"p-value of paired t-test between OLS and Ridge:\", p_)     \n",
    "to compare the performance of different models (as we did during the lab). Make a\n",
    "conclusion about this dataset and your ability to predict the outcome with the models\n",
    "at hand.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
