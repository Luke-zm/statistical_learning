{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "511d57bd",
   "metadata": {},
   "source": [
    "# Case Study 2: Predicting bank loan defaults and credit scores\n",
    "\n",
    "You are a data scientist working for a consumer bank that wants to use their data on customer savings, loans, and spending habits to predict whether they will default on a loan. They also want to know if they can predict what credit score a credit rating agency will give them.\n",
    "\n",
    "They give you a dataset 'credit_score.csv' of 1000 customers who took out loans recently and ask you to see if there is any \"signal\" in the data to make this prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6f5e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CUST_ID  INCOME  SAVINGS     DEBT  R_SAVINGS_INCOME  R_DEBT_INCOME  \\\n",
      "0    C02COQEVYU   33269        0   532304            0.0000        16.0000   \n",
      "1    C02OZKC0ZF   77158    91187   315648            1.1818         4.0909   \n",
      "2    C03FHP2D0A   30917    21642   534864            0.7000        17.3000   \n",
      "3    C03PVPPHOY   80657    64526   629125            0.8000         7.8000   \n",
      "4    C04J69MUX0  149971  1172498  2399531            7.8182        16.0000   \n",
      "..          ...     ...      ...      ...               ...            ...   \n",
      "995  CZQHJC9HDH  328892  1465066  5501471            4.4546        16.7273   \n",
      "996  CZRA4MLB0P   81404    88805   680837            1.0909         8.3637   \n",
      "997  CZSOD1KVFX       0    42428    30760            3.2379         8.1889   \n",
      "998  CZWC76UAUT   36011     8002   604181            0.2222        16.7777   \n",
      "999  CZZV5B3SAL   44266   309859    44266            6.9999         1.0000   \n",
      "\n",
      "     R_DEBT_SAVINGS  T_CLOTHING_12  T_CLOTHING_6  R_CLOTHING  ...  \\\n",
      "0            1.2000           1889           945      0.5003  ...   \n",
      "1            3.4615           5818           111      0.0191  ...   \n",
      "2           24.7142           1157           860      0.7433  ...   \n",
      "3            9.7499           6857          3686      0.5376  ...   \n",
      "4            2.0465           1978           322      0.1628  ...   \n",
      "..              ...            ...           ...         ...  ...   \n",
      "995          3.7551          16701         10132      0.6067  ...   \n",
      "996          7.6667           5400          1936      0.3585  ...   \n",
      "997          0.7250              0             0      0.8779  ...   \n",
      "998         75.5037           1993          1271      0.6377  ...   \n",
      "999          0.1429           1574          1264      0.8030  ...   \n",
      "\n",
      "     R_EXPENDITURE_SAVINGS  R_EXPENDITURE_DEBT  CAT_GAMBLING  CAT_DEBT  \\\n",
      "0                   0.0000              0.0625          High         1   \n",
      "1                   0.7692              0.2222            No         1   \n",
      "2                   1.4286              0.0578          High         1   \n",
      "3                   1.2500              0.1282          High         1   \n",
      "4                   0.1163              0.0568          High         1   \n",
      "..                     ...                 ...           ...       ...   \n",
      "995                 0.2041              0.0543          High         1   \n",
      "996                 0.8333              0.1087            No         1   \n",
      "997                 0.2500              0.3448            No         1   \n",
      "998                 5.0002              0.0662            No         1   \n",
      "999                 0.1587              1.1111            No         1   \n",
      "\n",
      "     CAT_CREDIT_CARD  CAT_MORTGAGE  CAT_SAVINGS_ACCOUNT  CAT_DEPENDENTS  \\\n",
      "0                  0             0                    0               0   \n",
      "1                  0             0                    1               0   \n",
      "2                  0             0                    1               0   \n",
      "3                  0             0                    1               0   \n",
      "4                  1             1                    1               1   \n",
      "..               ...           ...                  ...             ...   \n",
      "995                1             1                    1               1   \n",
      "996                0             0                    1               0   \n",
      "997                0             0                    1               0   \n",
      "998                1             0                    1               0   \n",
      "999                0             0                    1               0   \n",
      "\n",
      "     CREDIT_SCORE  DEFAULT  \n",
      "0             444        1  \n",
      "1             625        0  \n",
      "2             469        1  \n",
      "3             559        0  \n",
      "4             473        0  \n",
      "..            ...      ...  \n",
      "995           418        0  \n",
      "996           589        1  \n",
      "997           499        0  \n",
      "998           507        0  \n",
      "999           657        0  \n",
      "\n",
      "[1000 rows x 87 columns]\n"
     ]
    }
   ],
   "source": [
    "# load numpy and pandas and the dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/credit_score.csv')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b6f71d",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "Here are steps I recommend to process the data in preparation for analysis.\n",
    "\n",
    "- We see the column 'CUST_ID', which we can guess is the customer ID and should not be used as a predictor. Check that these are unique for every entry in the dataset, and then remove it from the columns.\n",
    "- The targets are 'DEFAULT' (whether a loan defaulted or not) and 'CREDIT_SCORE' (the customers credit score). Set both of these apart for analyses later.\n",
    "- Create your DataFrame of predictors. Check if any need to be processed as categorical variables. If so, do it like we did last week, or you can look at the function pd.get_dummies(), which can help you easily make one-hot encodings.\n",
    "- Take note of which are real-valued and likely need to be standardized before analyses later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f08636",
   "metadata": {},
   "source": [
    "To make life easier, I looked at the data in Excel and the below column names are the ones I think you should try to standardize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e587d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_normalize = [\n",
    "    'INCOME', 'SAVINGS', 'DEBT', 'R_SAVINGS_INCOME', 'R_DEBT_INCOME',\n",
    "       'R_DEBT_SAVINGS', 'T_CLOTHING_12', 'T_CLOTHING_6', 'R_CLOTHING',\n",
    "       'R_CLOTHING_INCOME', 'R_CLOTHING_SAVINGS', 'R_CLOTHING_DEBT',\n",
    "       'T_EDUCATION_12', 'T_EDUCATION_6', 'R_EDUCATION', 'R_EDUCATION_INCOME',\n",
    "       'R_EDUCATION_SAVINGS', 'R_EDUCATION_DEBT', 'T_ENTERTAINMENT_12',\n",
    "       'T_ENTERTAINMENT_6', 'R_ENTERTAINMENT', 'R_ENTERTAINMENT_INCOME',\n",
    "       'R_ENTERTAINMENT_SAVINGS', 'R_ENTERTAINMENT_DEBT', 'T_FINES_12',\n",
    "       'T_FINES_6', 'R_FINES', 'R_FINES_INCOME', 'R_FINES_SAVINGS',\n",
    "       'R_FINES_DEBT', 'T_GAMBLING_12', 'T_GAMBLING_6', 'R_GAMBLING',\n",
    "       'R_GAMBLING_INCOME', 'R_GAMBLING_SAVINGS', 'R_GAMBLING_DEBT',\n",
    "       'T_GROCERIES_12', 'T_GROCERIES_6', 'R_GROCERIES', 'R_GROCERIES_INCOME',\n",
    "       'R_GROCERIES_SAVINGS', 'R_GROCERIES_DEBT', 'T_HEALTH_12', 'T_HEALTH_6',\n",
    "       'R_HEALTH', 'R_HEALTH_INCOME', 'R_HEALTH_SAVINGS', 'R_HEALTH_DEBT',\n",
    "       'T_HOUSING_12', 'T_HOUSING_6', 'R_HOUSING', 'R_HOUSING_INCOME',\n",
    "       'R_HOUSING_SAVINGS', 'R_HOUSING_DEBT', 'T_TAX_12', 'T_TAX_6', 'R_TAX',\n",
    "       'R_TAX_INCOME', 'R_TAX_SAVINGS', 'R_TAX_DEBT', 'T_TRAVEL_12',\n",
    "       'T_TRAVEL_6', 'R_TRAVEL', 'R_TRAVEL_INCOME', 'R_TRAVEL_SAVINGS',\n",
    "       'R_TRAVEL_DEBT', 'T_UTILITIES_12', 'T_UTILITIES_6', 'R_UTILITIES',\n",
    "       'R_UTILITIES_INCOME', 'R_UTILITIES_SAVINGS', 'R_UTILITIES_DEBT',\n",
    "       'T_EXPENDITURE_12', 'T_EXPENDITURE_6', 'R_EXPENDITURE',\n",
    "       'R_EXPENDITURE_INCOME', 'R_EXPENDITURE_SAVINGS', 'R_EXPENDITURE_DEBT',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55853e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check CUST_ID is unique\n",
    "print(df['CUST_ID'].is_unique)\n",
    "# Drop CUST_ID if it is unique\n",
    "if df['CUST_ID'].is_unique:\n",
    "    df.drop(columns=['CUST_ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caf0f8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save y_default as the 1st target variable\n",
    "y_default = df['DEFAULT']\n",
    "# Drop y_default from the dataframe\n",
    "df.drop(columns=['DEFAULT'], inplace=True)\n",
    "\n",
    "# Save y_credit_score as the 2nd target variable\n",
    "y_credit_score = df['CREDIT_SCORE']\n",
    "# Drop y_credit_score from the dataframe\n",
    "df.drop(columns=['CREDIT_SCORE'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "706d1f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       INCOME   SAVINGS      DEBT  R_SAVINGS_INCOME  R_DEBT_INCOME  \\\n",
      "0   -0.777240 -0.933351 -0.263339         -1.024549       1.699167   \n",
      "1   -0.391097 -0.727370 -0.484123         -0.726575      -0.338334   \n",
      "2   -0.797934 -0.884465 -0.260730         -0.848054       1.921581   \n",
      "3   -0.360312 -0.787594 -0.164673         -0.822840       0.296247   \n",
      "4    0.249525  1.715197  1.639472          0.946701       1.699167   \n",
      "..        ...       ...       ...               ...            ...   \n",
      "995  1.823705  2.376077  4.800526          0.098616       1.823599   \n",
      "996 -0.353740 -0.732750 -0.111975         -0.749494       0.392689   \n",
      "997 -1.069947 -0.837511 -0.774441         -0.208158       0.362783   \n",
      "998 -0.753116 -0.915276 -0.190092         -0.968525       1.832222   \n",
      "999 -0.680487 -0.233413 -0.760677          0.740378      -0.867150   \n",
      "\n",
      "     R_DEBT_SAVINGS  T_CLOTHING_12  T_CLOTHING_6  R_CLOTHING  \\\n",
      "0         -0.278144      -0.659327     -0.492793    0.192660   \n",
      "1         -0.143371      -0.134234     -0.655799   -1.847030   \n",
      "2          1.123182      -0.757155     -0.509407    1.222678   \n",
      "3          0.231386       0.004624      0.042937    0.350766   \n",
      "4         -0.227697      -0.647432     -0.614559   -1.237920   \n",
      "..              ...            ...           ...         ...   \n",
      "995       -0.125874       1.320230      1.302811    0.643664   \n",
      "996        0.107238      -0.190097     -0.299102   -0.408395   \n",
      "997       -0.306452      -0.911783     -0.677494    1.793215   \n",
      "998        4.149977      -0.645428     -0.429077    0.775066   \n",
      "999       -0.341142      -0.701425     -0.430445    1.475732   \n",
      "\n",
      "     R_CLOTHING_INCOME  ...  R_EXPENDITURE  R_EXPENDITURE_INCOME  \\\n",
      "0             0.033098  ...       0.842411              0.333879   \n",
      "1             0.528442  ...      -1.939268             -0.204296   \n",
      "2            -0.483552  ...       0.718195              0.333879   \n",
      "3             0.784103  ...      -0.176409              0.333879   \n",
      "4            -1.128032  ...      -0.654451             -0.204296   \n",
      "..                 ...  ...            ...                   ...   \n",
      "995          -0.126691  ...       0.084570             -0.204296   \n",
      "996           0.286096  ...      -1.096107             -0.204296   \n",
      "997          -1.354399  ...       2.887578              0.729369   \n",
      "998          -0.006850  ...       1.726977              0.991649   \n",
      "999          -0.531488  ...      -0.483811              0.991649   \n",
      "\n",
      "     R_EXPENDITURE_SAVINGS  R_EXPENDITURE_DEBT  CAT_GAMBLING  CAT_DEBT  \\\n",
      "0                -0.562241           -0.417928          High         1   \n",
      "1                -0.088731           -0.294962            No         1   \n",
      "2                 0.317187           -0.421547          High         1   \n",
      "3                 0.207243           -0.367340          High         1   \n",
      "4                -0.490648           -0.422317          High         1   \n",
      "..                     ...                 ...           ...       ...   \n",
      "995              -0.436599           -0.424242          High         1   \n",
      "996              -0.049272           -0.382355            No         1   \n",
      "997              -0.408344           -0.200562            No         1   \n",
      "998               2.515818           -0.415079            No         1   \n",
      "999              -0.464547            0.389475            No         1   \n",
      "\n",
      "     CAT_CREDIT_CARD  CAT_MORTGAGE  CAT_SAVINGS_ACCOUNT  CAT_DEPENDENTS  \n",
      "0                  0             0                    0               0  \n",
      "1                  0             0                    1               0  \n",
      "2                  0             0                    1               0  \n",
      "3                  0             0                    1               0  \n",
      "4                  1             1                    1               1  \n",
      "..               ...           ...                  ...             ...  \n",
      "995                1             1                    1               1  \n",
      "996                0             0                    1               0  \n",
      "997                0             0                    1               0  \n",
      "998                1             0                    1               0  \n",
      "999                0             0                    1               0  \n",
      "\n",
      "[1000 rows x 84 columns]\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data using standard scaler from sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
    "# display the normalized dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36218238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CAT_GAMBLING'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Find the columns with object datatype\n",
    "object_columns = df.select_dtypes(include='object').columns\n",
    "# Print the name of the columns with object datatype\n",
    "print(object_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "962e44ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 85 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   INCOME                   1000 non-null   float64\n",
      " 1   SAVINGS                  1000 non-null   float64\n",
      " 2   DEBT                     1000 non-null   float64\n",
      " 3   R_SAVINGS_INCOME         1000 non-null   float64\n",
      " 4   R_DEBT_INCOME            1000 non-null   float64\n",
      " 5   R_DEBT_SAVINGS           1000 non-null   float64\n",
      " 6   T_CLOTHING_12            1000 non-null   float64\n",
      " 7   T_CLOTHING_6             1000 non-null   float64\n",
      " 8   R_CLOTHING               1000 non-null   float64\n",
      " 9   R_CLOTHING_INCOME        1000 non-null   float64\n",
      " 10  R_CLOTHING_SAVINGS       1000 non-null   float64\n",
      " 11  R_CLOTHING_DEBT          1000 non-null   float64\n",
      " 12  T_EDUCATION_12           1000 non-null   float64\n",
      " 13  T_EDUCATION_6            1000 non-null   float64\n",
      " 14  R_EDUCATION              1000 non-null   float64\n",
      " 15  R_EDUCATION_INCOME       1000 non-null   float64\n",
      " 16  R_EDUCATION_SAVINGS      1000 non-null   float64\n",
      " 17  R_EDUCATION_DEBT         1000 non-null   float64\n",
      " 18  T_ENTERTAINMENT_12       1000 non-null   float64\n",
      " 19  T_ENTERTAINMENT_6        1000 non-null   float64\n",
      " 20  R_ENTERTAINMENT          1000 non-null   float64\n",
      " 21  R_ENTERTAINMENT_INCOME   1000 non-null   float64\n",
      " 22  R_ENTERTAINMENT_SAVINGS  1000 non-null   float64\n",
      " 23  R_ENTERTAINMENT_DEBT     1000 non-null   float64\n",
      " 24  T_FINES_12               1000 non-null   float64\n",
      " 25  T_FINES_6                1000 non-null   float64\n",
      " 26  R_FINES                  1000 non-null   float64\n",
      " 27  R_FINES_INCOME           1000 non-null   float64\n",
      " 28  R_FINES_SAVINGS          1000 non-null   float64\n",
      " 29  R_FINES_DEBT             1000 non-null   float64\n",
      " 30  T_GAMBLING_12            1000 non-null   float64\n",
      " 31  T_GAMBLING_6             1000 non-null   float64\n",
      " 32  R_GAMBLING               1000 non-null   float64\n",
      " 33  R_GAMBLING_INCOME        1000 non-null   float64\n",
      " 34  R_GAMBLING_SAVINGS       1000 non-null   float64\n",
      " 35  R_GAMBLING_DEBT          1000 non-null   float64\n",
      " 36  T_GROCERIES_12           1000 non-null   float64\n",
      " 37  T_GROCERIES_6            1000 non-null   float64\n",
      " 38  R_GROCERIES              1000 non-null   float64\n",
      " 39  R_GROCERIES_INCOME       1000 non-null   float64\n",
      " 40  R_GROCERIES_SAVINGS      1000 non-null   float64\n",
      " 41  R_GROCERIES_DEBT         1000 non-null   float64\n",
      " 42  T_HEALTH_12              1000 non-null   float64\n",
      " 43  T_HEALTH_6               1000 non-null   float64\n",
      " 44  R_HEALTH                 1000 non-null   float64\n",
      " 45  R_HEALTH_INCOME          1000 non-null   float64\n",
      " 46  R_HEALTH_SAVINGS         1000 non-null   float64\n",
      " 47  R_HEALTH_DEBT            1000 non-null   float64\n",
      " 48  T_HOUSING_12             1000 non-null   float64\n",
      " 49  T_HOUSING_6              1000 non-null   float64\n",
      " 50  R_HOUSING                1000 non-null   float64\n",
      " 51  R_HOUSING_INCOME         1000 non-null   float64\n",
      " 52  R_HOUSING_SAVINGS        1000 non-null   float64\n",
      " 53  R_HOUSING_DEBT           1000 non-null   float64\n",
      " 54  T_TAX_12                 1000 non-null   float64\n",
      " 55  T_TAX_6                  1000 non-null   float64\n",
      " 56  R_TAX                    1000 non-null   float64\n",
      " 57  R_TAX_INCOME             1000 non-null   float64\n",
      " 58  R_TAX_SAVINGS            1000 non-null   float64\n",
      " 59  R_TAX_DEBT               1000 non-null   float64\n",
      " 60  T_TRAVEL_12              1000 non-null   float64\n",
      " 61  T_TRAVEL_6               1000 non-null   float64\n",
      " 62  R_TRAVEL                 1000 non-null   float64\n",
      " 63  R_TRAVEL_INCOME          1000 non-null   float64\n",
      " 64  R_TRAVEL_SAVINGS         1000 non-null   float64\n",
      " 65  R_TRAVEL_DEBT            1000 non-null   float64\n",
      " 66  T_UTILITIES_12           1000 non-null   float64\n",
      " 67  T_UTILITIES_6            1000 non-null   float64\n",
      " 68  R_UTILITIES              1000 non-null   float64\n",
      " 69  R_UTILITIES_INCOME       1000 non-null   float64\n",
      " 70  R_UTILITIES_SAVINGS      1000 non-null   float64\n",
      " 71  R_UTILITIES_DEBT         1000 non-null   float64\n",
      " 72  T_EXPENDITURE_12         1000 non-null   float64\n",
      " 73  T_EXPENDITURE_6          1000 non-null   float64\n",
      " 74  R_EXPENDITURE            1000 non-null   float64\n",
      " 75  R_EXPENDITURE_INCOME     1000 non-null   float64\n",
      " 76  R_EXPENDITURE_SAVINGS    1000 non-null   float64\n",
      " 77  R_EXPENDITURE_DEBT       1000 non-null   float64\n",
      " 78  CAT_DEBT                 1000 non-null   int64  \n",
      " 79  CAT_CREDIT_CARD          1000 non-null   int64  \n",
      " 80  CAT_MORTGAGE             1000 non-null   int64  \n",
      " 81  CAT_SAVINGS_ACCOUNT      1000 non-null   int64  \n",
      " 82  CAT_DEPENDENTS           1000 non-null   int64  \n",
      " 83  CAT_GAMBLING_Low         1000 non-null   bool   \n",
      " 84  CAT_GAMBLING_No          1000 non-null   bool   \n",
      "dtypes: bool(2), float64(78), int64(5)\n",
      "memory usage: 650.5 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INCOME</th>\n",
       "      <th>SAVINGS</th>\n",
       "      <th>DEBT</th>\n",
       "      <th>R_SAVINGS_INCOME</th>\n",
       "      <th>R_DEBT_INCOME</th>\n",
       "      <th>R_DEBT_SAVINGS</th>\n",
       "      <th>T_CLOTHING_12</th>\n",
       "      <th>T_CLOTHING_6</th>\n",
       "      <th>R_CLOTHING</th>\n",
       "      <th>R_CLOTHING_INCOME</th>\n",
       "      <th>...</th>\n",
       "      <th>R_EXPENDITURE_INCOME</th>\n",
       "      <th>R_EXPENDITURE_SAVINGS</th>\n",
       "      <th>R_EXPENDITURE_DEBT</th>\n",
       "      <th>CAT_DEBT</th>\n",
       "      <th>CAT_CREDIT_CARD</th>\n",
       "      <th>CAT_MORTGAGE</th>\n",
       "      <th>CAT_SAVINGS_ACCOUNT</th>\n",
       "      <th>CAT_DEPENDENTS</th>\n",
       "      <th>CAT_GAMBLING_Low</th>\n",
       "      <th>CAT_GAMBLING_No</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.777240</td>\n",
       "      <td>-0.933351</td>\n",
       "      <td>-0.263339</td>\n",
       "      <td>-1.024549</td>\n",
       "      <td>1.699167</td>\n",
       "      <td>-0.278144</td>\n",
       "      <td>-0.659327</td>\n",
       "      <td>-0.492793</td>\n",
       "      <td>0.192660</td>\n",
       "      <td>0.033098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333879</td>\n",
       "      <td>-0.562241</td>\n",
       "      <td>-0.417928</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.391097</td>\n",
       "      <td>-0.727370</td>\n",
       "      <td>-0.484123</td>\n",
       "      <td>-0.726575</td>\n",
       "      <td>-0.338334</td>\n",
       "      <td>-0.143371</td>\n",
       "      <td>-0.134234</td>\n",
       "      <td>-0.655799</td>\n",
       "      <td>-1.847030</td>\n",
       "      <td>0.528442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204296</td>\n",
       "      <td>-0.088731</td>\n",
       "      <td>-0.294962</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.797934</td>\n",
       "      <td>-0.884465</td>\n",
       "      <td>-0.260730</td>\n",
       "      <td>-0.848054</td>\n",
       "      <td>1.921581</td>\n",
       "      <td>1.123182</td>\n",
       "      <td>-0.757155</td>\n",
       "      <td>-0.509407</td>\n",
       "      <td>1.222678</td>\n",
       "      <td>-0.483552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333879</td>\n",
       "      <td>0.317187</td>\n",
       "      <td>-0.421547</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.360312</td>\n",
       "      <td>-0.787594</td>\n",
       "      <td>-0.164673</td>\n",
       "      <td>-0.822840</td>\n",
       "      <td>0.296247</td>\n",
       "      <td>0.231386</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>0.042937</td>\n",
       "      <td>0.350766</td>\n",
       "      <td>0.784103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333879</td>\n",
       "      <td>0.207243</td>\n",
       "      <td>-0.367340</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.249525</td>\n",
       "      <td>1.715197</td>\n",
       "      <td>1.639472</td>\n",
       "      <td>0.946701</td>\n",
       "      <td>1.699167</td>\n",
       "      <td>-0.227697</td>\n",
       "      <td>-0.647432</td>\n",
       "      <td>-0.614559</td>\n",
       "      <td>-1.237920</td>\n",
       "      <td>-1.128032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204296</td>\n",
       "      <td>-0.490648</td>\n",
       "      <td>-0.422317</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     INCOME   SAVINGS      DEBT  R_SAVINGS_INCOME  R_DEBT_INCOME  \\\n",
       "0 -0.777240 -0.933351 -0.263339         -1.024549       1.699167   \n",
       "1 -0.391097 -0.727370 -0.484123         -0.726575      -0.338334   \n",
       "2 -0.797934 -0.884465 -0.260730         -0.848054       1.921581   \n",
       "3 -0.360312 -0.787594 -0.164673         -0.822840       0.296247   \n",
       "4  0.249525  1.715197  1.639472          0.946701       1.699167   \n",
       "\n",
       "   R_DEBT_SAVINGS  T_CLOTHING_12  T_CLOTHING_6  R_CLOTHING  R_CLOTHING_INCOME  \\\n",
       "0       -0.278144      -0.659327     -0.492793    0.192660           0.033098   \n",
       "1       -0.143371      -0.134234     -0.655799   -1.847030           0.528442   \n",
       "2        1.123182      -0.757155     -0.509407    1.222678          -0.483552   \n",
       "3        0.231386       0.004624      0.042937    0.350766           0.784103   \n",
       "4       -0.227697      -0.647432     -0.614559   -1.237920          -1.128032   \n",
       "\n",
       "   ...  R_EXPENDITURE_INCOME  R_EXPENDITURE_SAVINGS  R_EXPENDITURE_DEBT  \\\n",
       "0  ...              0.333879              -0.562241           -0.417928   \n",
       "1  ...             -0.204296              -0.088731           -0.294962   \n",
       "2  ...              0.333879               0.317187           -0.421547   \n",
       "3  ...              0.333879               0.207243           -0.367340   \n",
       "4  ...             -0.204296              -0.490648           -0.422317   \n",
       "\n",
       "   CAT_DEBT  CAT_CREDIT_CARD  CAT_MORTGAGE  CAT_SAVINGS_ACCOUNT  \\\n",
       "0         1                0             0                    0   \n",
       "1         1                0             0                    1   \n",
       "2         1                0             0                    1   \n",
       "3         1                0             0                    1   \n",
       "4         1                1             1                    1   \n",
       "\n",
       "   CAT_DEPENDENTS  CAT_GAMBLING_Low  CAT_GAMBLING_No  \n",
       "0               0             False            False  \n",
       "1               0             False             True  \n",
       "2               0             False            False  \n",
       "3               0             False            False  \n",
       "4               1             False            False  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply one-hot encoding to the object columns using get_dummies\n",
    "df = pd.get_dummies(df, columns=object_columns, drop_first=True)\n",
    "# Check all columns are numeric\n",
    "print(df.info())\n",
    "# Print the first 5 rows of the dataframe\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4e445a",
   "metadata": {},
   "source": [
    "## Classification experiment\n",
    "\n",
    "Now predict the binary label 'DEFAULT'. Run an experiment comparing Logistic regression with no regularization, with L1 regularization, and with L2 regularization. You should probably run multiple cross validation splits, like last week.\n",
    "\n",
    "Since this is a classification experiment, use the AUC score as your performance metric. Scikit-learn has the method: 'sklearn.metrics.roc_auc_score'.\n",
    "\n",
    "Getting the Logistic Regression models to behave well requires some tweaking. I have done this for you to save you some time, but in the future you should get used to playing around with them and figuring out good settings yourself. Use the following method calls, where the training dataset needs to be created appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce18240e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nUse the methods like this, which should look similar to what we did last week:\\n\\n    clf = LogisticRegression(penalty=None, max_iter=10000)  # uses 5-fold cross validation by default\\n    clf.fit(X_train, Y_train)  # the .fit method operates on the clf object in-place\\n    Y_pred = clf.predict_proba(X_test)  # this gives us the probabilities of each label\\n    print(clf.classes_)  # look at this to see the order of the labels in Y_pred\\n    Y_pred_P1 = Y_pred[:, 1]  # so this is the probability of assigning Y=1\\n    \\nFor L1 regularization, the following settings performed well for me:\\n\\n    clf = LogisticRegressionCV(penalty='l1', solver='saga', max_iter=10000)  # uses 5-fold cross validation by default\\n    \\nAnd finally for L2 regularization, the following settings performed well for me:\\n\\n    clf = LogisticRegressionCV(penalty='l2', max_iter=10000)  # uses 5-fold cross validation by default\\n\\nYou use roc_auc_score like this (definitely google the documentation for all of these methods):\\n\\n    auc = roc_auc_score(Y_test, Y_pred_P1)\\n    \\nwhere Y_test is a vector of the true 0-1 labels and Y_pred_P1 is a corresponding vector of PROBABILITIES for Y=1.\\nSee the example code I wrote above to see how to predict the probabilities P(Y=1).\\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression  # logistic regression with optionally built in regularization.\n",
    "from sklearn.linear_model import LogisticRegressionCV  # logistic regression with built in regularization. The penalty parameter is Cross-validated\n",
    "from sklearn.metrics import roc_auc_score # computes the AUC score\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Use the methods like this, which should look similar to what we did last week:\n",
    "\n",
    "    clf = LogisticRegression(penalty=None, max_iter=10000)  # uses 5-fold cross validation by default\n",
    "    clf.fit(X_train, Y_train)  # the .fit method operates on the clf object in-place\n",
    "    Y_pred = clf.predict_proba(X_test)  # this gives us the probabilities of each label\n",
    "    print(clf.classes_)  # look at this to see the order of the labels in Y_pred\n",
    "    Y_pred_P1 = Y_pred[:, 1]  # so this is the probability of assigning Y=1\n",
    "    \n",
    "For L1 regularization, the following settings performed well for me:\n",
    "\n",
    "    clf = LogisticRegressionCV(penalty='l1', solver='saga', max_iter=10000)  # uses 5-fold cross validation by default\n",
    "    \n",
    "And finally for L2 regularization, the following settings performed well for me:\n",
    "\n",
    "    clf = LogisticRegressionCV(penalty='l2', max_iter=10000)  # uses 5-fold cross validation by default\n",
    "\n",
    "You use roc_auc_score like this (definitely google the documentation for all of these methods):\n",
    "\n",
    "    auc = roc_auc_score(Y_test, Y_pred_P1)\n",
    "    \n",
    "where Y_test is a vector of the true 0-1 labels and Y_pred_P1 is a corresponding vector of PROBABILITIES for Y=1.\n",
    "See the example code I wrote above to see how to predict the probabilities P(Y=1).\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b988df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a stratified train-test split with 20% of the data in the test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df, y_default, test_size=0.2, stratify=y_default, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4b10614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/zhiming/miniconda3/envs/stat_learning/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Instead of K-fold cross validation, I will just take random subsets of the dataset, which is easier to implement.\n",
    "n_cv = 20\n",
    "\n",
    "errors_lr = []  # these are containers to hold the test set errors\n",
    "errors_ridge = []\n",
    "errors_lasso = []\n",
    "auc_lr = []\n",
    "auc_ridge = []\n",
    "auc_lasso = []\n",
    "\n",
    "indices = list(range(len(df)))  # how we will index the dataset\n",
    "n_train = int(len(df) * .80)  # each split will have 80% train and 20% test\n",
    "\n",
    "# iterate through the test sets\n",
    "for k in range(n_cv):\n",
    "    \n",
    "    np.random.shuffle(indices)  # shuffle the indices. this function works in-place\n",
    "    train_inds = indices[:n_train]  # slice out the training indices\n",
    "    test_inds = indices[n_train:]\n",
    "\n",
    "    Y_train = y_default.iloc[train_inds]  # it is very important to remember to use iloc if using integer index\n",
    "    X_train = df.iloc[train_inds, :].copy()\n",
    "    \n",
    "    Y_test = y_default.iloc[test_inds]\n",
    "    X_test = df.iloc[test_inds, :].copy()\n",
    "    \n",
    "    # standardize the predictors (don't standardize the gender variable)\n",
    "    for feature_name in columns_to_normalize:\n",
    "        mean_ = X_train[feature_name].mean()\n",
    "        std_ = X_train[feature_name].std()\n",
    "        X_train[feature_name] = (X_train[feature_name] - mean_) / std_\n",
    "        X_test[feature_name] = (X_test[feature_name] - mean_) / std_  # we must use the training statistics to transform the test set!\n",
    "    \n",
    "    # Now fit the models on the training set and predict the test targets\n",
    "    lr = LogisticRegression(fit_intercept=True).fit(X_train, Y_train)  # Linear regression with an intercept. Do NOT use X_ from statsmodels.\n",
    "    Y_pred = lr.predict(X_test)  # prediction on a test set\n",
    "    rmse = np.sqrt(np.mean((Y_test - Y_pred) ** 2))  # root mean squared error is more interpretable than MSE\n",
    "    errors_lr.append(rmse)\n",
    "    auc = roc_auc_score(Y_test, Y_pred)\n",
    "    auc_lr.append(auc)\n",
    "\n",
    "\n",
    "    ridge = LogisticRegressionCV(penalty='l1', solver='saga', max_iter=10000).fit(X_train, Y_train)  # Ridge regression with an intercept. Selects the penalty from among 0.1, 1.0, and 10 using 5-fold cross validation.\n",
    "    Y_pred = ridge.predict(X_test) \n",
    "    rmse = np.sqrt(np.mean((Y_test - Y_pred) ** 2))\n",
    "    errors_ridge.append(rmse)\n",
    "    auc = roc_auc_score(Y_test, Y_pred)\n",
    "    auc_ridge.append(auc)\n",
    "\n",
    "    lasso =LogisticRegressionCV(penalty='l2', max_iter=10000).fit(X_train, Y_train)  # Lasso with an intercept. Selects the penalty from among 0.1, 1.0, and 10 using 5-fold cross validation.\n",
    "    Y_pred = lasso.predict(X_test)\n",
    "    rmse = np.sqrt(np.mean((Y_test - Y_pred) ** 2))\n",
    "    errors_lasso.append(rmse)\n",
    "    auc = roc_auc_score(Y_test, Y_pred)\n",
    "    auc_lasso.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17404be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.572018841961581\n",
      "0.5527969497392814\n",
      "0.5464016256872268\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(auc_lr))\n",
    "print(np.mean(auc_ridge))\n",
    "print(np.mean(auc_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e20693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f94251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "face37a6",
   "metadata": {},
   "source": [
    "## Regression on discrete data\n",
    "\n",
    "We now move on to the second part of the job, which is to try to predict the credit score (column name is 'CREDIT_SCORE'). Explore the data in this variable and decide what type of model from lecture is most appropriate.\n",
    "\n",
    "Depending on what you decide, the below methods from Scikit-learn can be used. You should again be comparing different models on multiple cross validation splits.\n",
    "\n",
    "As an evaluation metric, what should you use? There are different choices, but for now why don't you just try to use Root mean squared error (like last week).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1caf520e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor Ridge regression, everything worked fine out of the box for me:\\n    \\n    model = RidgeCV()  # uses 5-fold cross validation by default\\n    model.fit(X_train, Y_train)  \\n    Y_pred = model.predict(X_test) \\n    \\nFor Lasso, the following worked well for me:\\n\\n    model = LassoCV(max_iter=2000)  # uses 5-fold cross validation by default\\n\\nAnd for Poisson Regression, the following setting worked well for me.\\n\\n    model = PoissonRegressor(max_iter=10000)\\n\\nNote that, while PoissonRegressor uses L2 regularization by default with a penalty parameter set to alpha=2,\\nit does not cross validate a good value for this parameter the way RidgeCV and LassoCV do for you. \\n\\nSo you could consider cross validating this parameter using the sklearn.model_selection.GridSearchCV method.\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV, PoissonRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\"\"\"\n",
    "For Ridge regression, everything worked fine out of the box for me:\n",
    "    \n",
    "    model = RidgeCV()  # uses 5-fold cross validation by default\n",
    "    model.fit(X_train, Y_train)  \n",
    "    Y_pred = model.predict(X_test) \n",
    "    \n",
    "For Lasso, the following worked well for me:\n",
    "\n",
    "    model = LassoCV(max_iter=2000)  # uses 5-fold cross validation by default\n",
    "\n",
    "And for Poisson Regression, the following setting worked well for me.\n",
    "\n",
    "    model = PoissonRegressor(max_iter=10000)\n",
    "\n",
    "Note that, while PoissonRegressor uses L2 regularization by default with a penalty parameter set to alpha=2,\n",
    "it does not cross validate a good value for this parameter the way RidgeCV and LassoCV do for you. \n",
    "\n",
    "So you could consider cross validating this parameter using the sklearn.model_selection.GridSearchCV method.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e97c258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
